{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adfbc628-58d4-4a27-bae9-342e49cdd1cf",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 100%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'> Snowflake Python Worksheet Demo</font></h3>\n",
    "\n",
    "* Snowflake Python Worksheetsã§åˆ†æã‚’è¡Œã†ãŸã‚ã®ã‚³ãƒ¼ãƒ‰ã®ä¾‹ã‚’ä»¥ä¸‹ã®webã‚µã‚¤ãƒˆã‹ã‚‰å¼•ç”¨ã—ã¾ã™ã€‚\n",
    "* Python Worksheetsã§æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã€œæ¨è«–ã¾ã§ã‚„ã£ã¦ã¿ãŸ\n",
    "( https://datumstudio.jp/blog/0724_snowflake_python-worksheets/) \n",
    "```Python\n",
    "# The Snowpark package is required for Python Worksheets. \n",
    "# You can add more packages by selecting them using the Packages control and then importing them.\n",
    "\n",
    "import snowflake.snowpark as snowpark\n",
    "from snowflake.snowpark.functions import col\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‹ã‚‰ã‚¹ãƒ†ãƒ¼ã‚¸ã¸ã®ä¿å­˜ã¾ã§\n",
    "from snowflake.snowpark.session import Session\n",
    "import pandas as pd\n",
    "import io\n",
    "import joblib\n",
    "# ãƒ¢ãƒ‡ãƒ«æº–å‚™\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# è©•ä¾¡æŒ‡æ¨™\n",
    "from sklearn.metrics import accuracy_score \n",
    "# å†…éƒ¨ã‚¹ãƒ†ãƒ¼ã‚¸ã«ç™»éŒ²ã™ã‚‹ãŸã‚ã®é–¢æ•°\n",
    "def save_file(session, model, path):\n",
    "    input_stream = io.BytesIO()\n",
    "    joblib.dump(model, input_stream)\n",
    "    # upload_streamãƒ¡ã‚½ãƒƒãƒ‰ã§å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’å†…éƒ¨ã‚¹ãƒ†ãƒ¼ã‚¸ã«ç™»éŒ²\n",
    "    session._conn._cursor.upload_stream(input_stream, path) \n",
    "    return  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1045d44e-d2dc-454f-9e6b-f5416776ecca",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #EFGG0F; font-size: 95%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>ğŸ¦„ Notes:</font></h3>\n",
    "\n",
    "ã“ã®é–¢æ•°ã¯ã€å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒã‚¤ãƒŠãƒªå½¢å¼ã§ä¿å­˜ã—ã€ãã®ãƒ¢ãƒ‡ãƒ«ã‚’Snowflakeãƒ‡ãƒ¼ã‚¿ã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹å†…ã®å†…éƒ¨ã‚¹ãƒ†ãƒ¼ã‚¸ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã®ã‚‚ã®ã§ã™ã€‚ä»¥ä¸‹ã¯é–¢æ•°å†…ã®å„ã‚¹ãƒ†ãƒƒãƒ—ã«ã¤ã„ã¦ã®è©³ç´°ã§ã™ï¼š\n",
    "\n",
    "* input_stream = io.BytesIO(): io.BytesIO() ã‚’ä½¿ç”¨ã—ã¦ã€ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ™‚çš„ã«æ ¼ç´ã™ã‚‹ãŸã‚ã®ãƒãƒƒãƒ•ã‚¡ï¼ˆãƒ¡ãƒ¢ãƒªå†…ã®ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã™ã‚‹ã‚¹ãƒˆãƒªãƒ¼ãƒ ï¼‰ã‚’ä½œæˆã—ã¾ã™ã€‚ã“ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã¯å¾Œã§ joblib.dump ã§ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚\n",
    "\n",
    "* joblib.dump(model, input_stream): joblib ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã® dump é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ã€å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ input_stream ã«ãƒã‚¤ãƒŠãƒªå½¢å¼ã§ä¿å­˜ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ãŒãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ãƒ¡ãƒ¢ãƒªå†…ã«æ ¼ç´ã•ã‚Œã¾ã™ã€‚\n",
    "\n",
    "* session._conn._cursor.upload_stream(input_stream, path): session ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå†…ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæƒ…å ±ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹å†…ã®å†…éƒ¨ã‚¹ãƒ†ãƒ¼ã‚¸ã«ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€upload_stream ãƒ¡ã‚½ãƒƒãƒ‰ãŒ input_stream ã®ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’æŒ‡å®šã•ã‚ŒãŸ path ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚path ã¯ã€ã‚¹ãƒ†ãƒ¼ã‚¸å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¾ã™ã€‚\n",
    "\n",
    "* return: ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒæˆåŠŸã—ãŸå ´åˆã€é–¢æ•°ã¯ä½•ã‚‚è¿”ã•ãšã«çµ‚äº†ã—ã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ãŠã‚ˆã³ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå¤±æ•—ã—ãŸå ´åˆã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
    "\n",
    "ã“ã®é–¢æ•°ã®ä¸»è¦ãªç›®çš„ã¯ã€å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’Snowflakeãƒ‡ãƒ¼ã‚¿ã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹å†…ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã«ä¿å­˜ã™ã‚‹ã“ã¨ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹å†…ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã«ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã§ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦äºˆæ¸¬ã‚„åˆ†æã‚’å®Ÿè¡Œã™ã‚‹éš›ã«ã€ãƒ¢ãƒ‡ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒå®¹æ˜“ã«ãªã‚Šã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ¼ã‚¿ã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹å†…ã«ä¿å­˜ã™ã‚‹ã“ã¨ã¯ã€ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚„è‡ªå‹•åŒ–ã‚¿ã‚¹ã‚¯ã®ä¸€éƒ¨ã¨ã—ã¦å½¹ç«‹ã¤ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0664a38-542a-45e4-93d1-42cfe738b6f2",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 100%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'></font></h3>\n",
    "    \n",
    "```Python\n",
    "# å®Ÿè¡Œé–¢æ•°\n",
    "def main(session: snowpark.Session):\n",
    "    # ãƒ¯ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ­ãƒ¼ãƒ‰ã¨æ•´å½¢\n",
    "    wine = load_wine()\n",
    "    df_local = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "    df_local['class'] = [wine.target_names[i] for i in wine.target]\n",
    "    df_local.columns = [x.upper() for x in df_local.columns]\n",
    "    df_snowpark = session.create_dataframe(df_local)\n",
    "    \n",
    "    # å­¦ç¿’ã€æ¤œè¨¼ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²ã—ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜\n",
    "    weights = [0.7, 0.2, 0.1]\n",
    "    dfsp_train, dfsp_val, dfsp_test = df_snowpark.random_split(weights, seed=42)\n",
    "    \n",
    "    dfsp_train.write.mode('overwrite').saveAsTable('wine_train')\n",
    "    dfsp_val.write.mode('overwrite').saveAsTable('wine_validation')\n",
    "    dfsp_test.write.mode('overwrite').saveAsTable('wine_test')\n",
    "    # å­¦ç¿’ã€æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®è¨­å®š\n",
    "    Xtrain = dfsp_train.drop('class').to_pandas() \n",
    "    ytrain = dfsp_train.select('class').to_pandas()\n",
    "    Xvalid = dfsp_val.drop('class').to_pandas()\n",
    "    yvalid = dfsp_val.select('class').to_pandas()\n",
    "    \n",
    "    # å­¦ç¿’ã®å®Ÿè¡Œ\n",
    "    model = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=5, random_state=42)\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã€ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦æ¤œè¨¼\n",
    "    predictions = model.predict(Xvalid)\n",
    "    accuracy = accuracy_score(yvalid, predictions)\n",
    "    # accuracyã®è©•ä¾¡çµæœã‚’resultã§è¿”ã™\n",
    "    result = session.create_dataframe([str(accuracy)], schema=['accuracy'])\n",
    "    # ä½¿ç”¨ã—ãŸæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã¨äºˆæ¸¬çµæœã‚’ãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜\n",
    "    df_tmp = pd.concat([dfsp_val.to_pandas(), pd.DataFrame(predictions , columns=['PREDICTION']) ], axis=1)\n",
    "    dfsp_pred = session.create_dataframe(df_tmp)\n",
    "    dfsp_pred.write.mode('overwrite').saveAsTable('wine_valid_pred')\n",
    "    # ãƒ¢ãƒ‡ãƒ«ã‚’å†…éƒ¨ã‚¹ãƒ†ãƒ¼ã‚¸ã«ä¿å­˜\n",
    "    model_stage = 'wine_models'\n",
    "    query = f\"\"\"create or replace stage {model_stage}\n",
    "             directory = (enable = true)\n",
    "             copy_options = (on_error='skip_file')\"\"\"\n",
    "    session.sql(query).collect()\n",
    "    # ä½œæˆã—ãŸã‚¹ãƒ†ãƒ¼ã‚¸ã«ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜\n",
    "    save_file(session, model, f'@{model_stage}/predict_class.joblib')\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a9d618-2900-4f4a-bcb7-fe08d81b7f8d",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #EFGG0F; font-size: 95%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>ğŸ¦„ Notes:</font></h3>\n",
    "\n",
    "\n",
    "| ã‚³ãƒ¼ãƒ‰ã®éƒ¨åˆ†                    | æ©Ÿèƒ½                                                                                   |\n",
    "|----------------------------------|---------------------------------------------------------------------------------------|\n",
    "| `model_stage = 'wine_models'`    | ã‚¹ãƒ†ãƒ¼ã‚¸ã®åå‰ã‚’å®šç¾©ã—ã¾ã™ã€‚å†…éƒ¨ã‚¹ãƒ†ãƒ¼ã‚¸ã«ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã®åå‰ã‚’æŒ‡å®šã—ã¾ã™ã€‚ |\n",
    "| `query`                          | SQLã‚¯ã‚¨ãƒªã‚’æ–‡å­—åˆ—ã¨ã—ã¦å®šç¾©ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å†…éƒ¨ã‚¹ãƒ†ãƒ¼ã‚¸ã‚’ä½œæˆã™ã‚‹ã‚¯ã‚¨ãƒªãŒç”Ÿæˆã•ã‚Œã¾ã™ã€‚    |\n",
    "| `f\"\"\"...\"\"\"`                    | ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«ï¼ˆfæ–‡å­—åˆ—ï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€ã‚¯ã‚¨ãƒªå†…ã«å¤‰æ•°ã‚„å¼ã‚’åŸ‹ã‚è¾¼ã¿ã¾ã™ã€‚`model_stage` ã®å€¤ã‚’åŸ‹ã‚è¾¼ã‚“ã§ã‚¹ãƒ†ãƒ¼ã‚¸åã‚’æŒ‡å®šã—ã¾ã™ã€‚ |\n",
    "| `create or replace stage {model_stage}...` | ã‚¹ãƒ†ãƒ¼ã‚¸ã‚’ä½œæˆã¾ãŸã¯ç½®ãæ›ãˆã‚‹SQLã‚¯ã‚¨ãƒªã§ã™ã€‚`model_stage` ã§æŒ‡å®šã•ã‚ŒãŸã‚¹ãƒ†ãƒ¼ã‚¸åã®å†…éƒ¨ã‚¹ãƒ†ãƒ¼ã‚¸ã‚’ä½œæˆã¾ãŸã¯ç½®ãæ›ãˆã¾ã™ã€‚ |\n",
    "| `directory = (enable = true)`     | ã‚¹ãƒ†ãƒ¼ã‚¸ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®šã‚’æŒ‡å®šã—ã¾ã™ã€‚`enable = true` ã¯ã‚¹ãƒ†ãƒ¼ã‚¸ã®æœ‰åŠ¹åŒ–ã‚’æ„å‘³ã—ã¾ã™ã€‚    |\n",
    "| `copy_options = (on_error='skip_file')` | ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ”ãƒ¼æ™‚ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¨­å®šã—ã¾ã™ã€‚ã“ã“ã§ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ”ãƒ¼æ™‚ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã€'skip_file' ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹è¨­å®šãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã™ã€‚ |\n",
    "| `session.sql(query).collect()`   | Snowflakeãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å¯¾ã—ã¦SQLã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã¾ã™ã€‚`query` ã®SQLã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã€çµæœã‚’åé›†ï¼ˆcollectï¼‰ã—ã¾ã™ã€‚     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393bc97b-6ac7-4846-aee4-e0f5a4023529",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 100%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'></font></h3>\n",
    "    \n",
    "```Python\n",
    "# å†…éƒ¨ã‚¹ãƒ†ãƒ¼ã‚¸ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ãƒ»æ¨è«–ã¾ã§\n",
    "import snowflake.snowpark as snowpark\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.files import SnowflakeFile\n",
    "import joblib\n",
    "import pandas as pd\n",
    "# ãƒ¢ãƒ‡ãƒ«æº–å‚™\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# å®Ÿè¡Œé–¢æ•°\n",
    "def main(session: snowpark.Session): \n",
    "    # å†…éƒ¨ã‚¹ãƒ†ãƒ¼ã‚¸ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰\n",
    "    model_stage = 'wine_models'\n",
    "    with SnowflakeFile.open(f'@{model_stage}/predict_class.joblib','rb', require_scoped_url = False) as file:\n",
    "        model = joblib.load(file)\n",
    "    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\n",
    "    dfsp_test = session.table('wine_test') \n",
    "    inputs = dfsp_test.drop('class').to_pandas()\n",
    "    \n",
    "    # ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹æ¨è«–\n",
    "    predictions = model.predict(inputs)\n",
    "    # æ¨è«–çµæœã®å‡ºåŠ›\n",
    "    df_tmp = pd.concat([dfsp_test.to_pandas(), pd.DataFrame(predictions , columns=['PREDICTION']) ], axis=1)\n",
    "    dfsp_test_pred = session.create_dataframe(df_tmp)\n",
    "    dfsp_test_pred.write.mode('overwrite').saveAsTable('wine_test_pred')\n",
    "    \n",
    "    return dfsp_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be715ee8-971c-4be9-8dae-9c369b131135",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #EFGG0F; font-size: 95%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>ğŸ¦„ Notes:</font></h3>\n",
    "\n",
    "\n",
    "æä¾›ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã¯ã€Snowflakeãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã§æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹äºˆæ¸¬ã‚’å®Ÿè¡Œã—ã€ãã®çµæœã‚’æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ã—ã¦ä¿å­˜ã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã«é–¢é€£ã™ã‚‹éƒ¨åˆ†ã¨ãã‚Œãã‚Œã®æ©Ÿèƒ½ã‚’èª¬æ˜ã—ã¾ã™ï¼š\n",
    "\n",
    "| ã‚³ãƒ¼ãƒ‰ | èª¬æ˜ |\n",
    "|-----------|-----------------------------------|\n",
    "| `import` ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆ | å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚Snowflakeã®é–¢é€£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿æ“ä½œã®ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€`joblib`ã€`pandas`ã€`RandomForestClassifier` ãªã©ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ |\n",
    "| `def main(session: snowpark.Session):` | `main` é–¢æ•°ã®å®šç¾©ã‚’é–‹å§‹ã—ã¾ã™ã€‚ã“ã®é–¢æ•°ã¯ã€Snowflakeã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å¼•æ•°ã¨ã—ã¦å—ã‘å–ã‚Šã¾ã™ã€‚ |\n",
    "| `model_stage = 'wine_models'` | ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜å ´æ‰€ã‚’æŒ‡å®šã™ã‚‹å¤‰æ•° `model_stage` ã‚’è¨­å®šã—ã¾ã™ã€‚ã“ã®å¤‰æ•°ã«ã¯ãƒ¢ãƒ‡ãƒ«ãŒä¿å­˜ã•ã‚ŒãŸã‚¹ãƒ†ãƒ¼ã‚¸ã®åå‰ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ã¨ä»®å®šã•ã‚Œã¦ã„ã¾ã™ã€‚ |\n",
    "| `with SnowflakeFile.open(f'@{model_stage}/predict_class.joblib','rb', require_scoped_url = False) as file:` | Snowflakeã®ã‚¹ãƒ†ãƒ¼ã‚¸ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚`@{model_stage}/predict_class.joblib` ã¯ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ã„ã¾ã™ã€‚ |\n",
    "| `model = joblib.load(file)` | `joblib` ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€`model` å¤‰æ•°ã«ãƒ¢ãƒ‡ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ ¼ç´ã—ã¾ã™ã€‚ |\n",
    "| `dfsp_test = session.table('wine_test')` | Snowflakeãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã® 'wine_test' ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ `dfsp_test` ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ã—ã¦èª­ã¿è¾¼ã¿ã¾ã™ã€‚ |\n",
    "| `inputs = dfsp_test.drop('class').to_pandas()` | 'wine_test' ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ 'class' åˆ—ã‚’é™¤ã„ãŸãƒ‡ãƒ¼ã‚¿ã‚’ `inputs` ã¨ã—ã¦å–å¾—ã—ã€Pandasãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›ã—ã¾ã™ã€‚ |\n",
    "| `predictions = model.predict(inputs)` | ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ `inputs` ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹äºˆæ¸¬ã‚’è¡Œã„ã€ãã®çµæœã‚’ `predictions` ã«æ ¼ç´ã—ã¾ã™ã€‚ |\n",
    "| `df_tmp = pd.concat([dfsp_test.to_pandas(), pd.DataFrame(predictions, columns=['PREDICTION'])], axis=1)` | å…ƒã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ  (`dfsp_test`) ã¨äºˆæ¸¬çµæœã‚’çµåˆã—ã¦æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ  `df_tmp` ã‚’ä½œæˆã—ã¾ã™ã€‚ |\n",
    "| `dfsp_test_pred = session.create_dataframe(df_tmp)` | æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ  `df_tmp` ã‚’ Snowflake ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã™ã‚‹æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ  `dfsp_test_pred` ã‚’ä½œæˆã—ã¾ã™ã€‚ |\n",
    "| `dfsp_test_pred.write.mode('overwrite').saveAsTable('wine_test_pred')` | æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ  `dfsp_test_pred` ã‚’ 'wine_test_pred' ã¨ã„ã†åå‰ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚ |\n",
    "| `return dfsp_test_pred` | æœ€çµ‚çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ  `dfsp_test_pred` ã‚’è¿”ã—ã¾ã™ã€‚ |\n",
    "\n",
    "ã“ã®ã‚³ãƒ¼ãƒ‰ã¯ã€Snowflakeãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹äºˆæ¸¬ã‚’è¡Œã„ã€ãã®äºˆæ¸¬çµæœã‚’æ–°ã—ã„ãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜ã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®é–¢æ•°ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f87a48-2d63-4bb0-ad1a-d3ab7217afc3",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 100%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>ã‚³ãƒ¼ãƒ‰ã®ãƒªãƒ¡ã‚¤ã‚¯1</font></h3>\n",
    "\n",
    "* ä¸Šè¨˜ã®ã‚³ãƒ¼ãƒ‰ã‚’ãƒªãƒ¡ã‚¤ã‚¯ã—ã¦ã¿ã¾ã—ãŸã€‚\n",
    "* ä»¥ä¸‹ã¯Snowflake Python Worksheetsã§SARIMAXãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦åˆ†æã™ã‚‹ä¾‹ã§ã™ã€‚\n",
    "* å¤‰æ•°åã€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åã¯å¤‰æ•°åˆ—'DATE'ã®ã¿æ˜ç¤ºçš„ã«ã—ã¦ãŠã‚Šã€ä»–ã¯ä»»æ„ã§ã™ã€‚\n",
    "  \n",
    "```Python\n",
    "# The Snowpark package is required for Python Worksheets. \n",
    "# You can add more packages by selecting them using the Packages control and then importing them.\n",
    "\n",
    "import snowflake.snowpark as snowpark\n",
    "\n",
    "from snowflake.snowpark.functions import month,year,col,sum\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa as tsa\n",
    "\n",
    "def main(session: snowpark.Session): \n",
    "    # Your code goes here, inside the \"main\" handler.\n",
    "    tableName = '-------------------'\n",
    "    dataframe = session.table(tableName).filter(col(\"---------\") == '---')\n",
    "    # Spark DataFrameã‹ã‚‰Pandas DataFrameã«å¤‰æ›\n",
    "    df = dataframe.toPandas()\n",
    "    # åˆ—åã‚’æŒ‡å®š\n",
    "    column_names = ['DATE', '-----', '-------------']\n",
    "    column_names = np.array(column_names)\n",
    "    \n",
    "    df = pd.DataFrame(df, columns=column_names)\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "   \n",
    "    # State Space Modelã®æ§‹ç¯‰\n",
    "    mod = sm.tsa.statespace.SARIMAX(df['---------'], \n",
    "                                order=(1, 1, 1),  # è‡ªå·±å›å¸°æ¬¡æ•°ã€å·®åˆ†æ¬¡æ•°ã€ç§»å‹•å¹³å‡æ¬¡æ•°\n",
    "                                seasonal_order=(1, 1, 1, 7),  # å­£ç¯€æ€§ã®è‡ªå·±å›å¸°æ¬¡æ•°ã€å·®åˆ†æ¬¡æ•°ã€ç§»å‹•å¹³å‡æ¬¡æ•°ã€å‘¨æœŸï¼ˆé€±æ¬¡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯7ï¼‰\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "\n",
    "    # ãƒ¢ãƒ‡ãƒ«ã®é©åˆ\n",
    "    results = mod.fit()\n",
    "    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¨å®šå€¤ã‚’å–å¾—\n",
    "    params = results.params\n",
    "\n",
    "    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’Pandas DataFrameã«å¤‰æ›\n",
    "    params_df = params.to_frame(name='Parameter_Estimate')\n",
    "\n",
    "    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰åˆ—ã«ç§»å‹•\n",
    "    params_df.reset_index(inplace=True)\n",
    "    params_df = params_df.rename(columns={'index': 'Parameter_Name'})\n",
    "\n",
    "\n",
    "    result = session.create_dataframe(params_df)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d28357-f9d5-455e-82b7-c12a7559e82f",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 100%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>ã‚³ãƒ¼ãƒ‰ã®ãƒªãƒ¡ã‚¤ã‚¯2</font></h3>\n",
    "    \n",
    "```Python\n",
    "# The Snowpark package is required for Python Worksheets. \n",
    "# You can add more packages by selecting them using the Packages control and then importing them.\n",
    "\n",
    "import snowflake.snowpark as snowpark\n",
    "\n",
    "from snowflake.snowpark.functions import month,year,col,sum\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa as tsa\n",
    "\n",
    "def main(session: snowpark.Session): \n",
    "    # Your code goes here, inside the \"main\" handler.\n",
    "    tableName = '-------------------'\n",
    "    dataframe = session.table(tableName).filter(col(\"---------\") == '---')\n",
    "    # Spark DataFrameã‹ã‚‰Pandas DataFrameã«å¤‰æ›\n",
    "    df = dataframe.toPandas()\n",
    "    # åˆ—åã‚’æŒ‡å®š\n",
    "    column_names = ['DATE', '-----', '-------------']\n",
    "    column_names = np.array(column_names)\n",
    "    \n",
    "    df = pd.DataFrame(df, columns=column_names)\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "   \n",
    "    # State Space Modelã®æ§‹ç¯‰\n",
    "    mod = sm.tsa.statespace.SARIMAX(df['---------'], \n",
    "                                order=(1, 1, 1),  # è‡ªå·±å›å¸°æ¬¡æ•°ã€å·®åˆ†æ¬¡æ•°ã€ç§»å‹•å¹³å‡æ¬¡æ•°\n",
    "                                seasonal_order=(1, 1, 1, 7),  # å­£ç¯€æ€§ã®è‡ªå·±å›å¸°æ¬¡æ•°ã€å·®åˆ†æ¬¡æ•°ã€ç§»å‹•å¹³å‡æ¬¡æ•°ã€å‘¨æœŸï¼ˆé€±æ¬¡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯7ï¼‰\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "\n",
    "    # ãƒ¢ãƒ‡ãƒ«ã®é©åˆ\n",
    "    results = mod.fit()\n",
    "    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¨å®šå€¤ã‚’å–å¾—\n",
    "    params = results.params\n",
    "\n",
    "    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’Pandas DataFrameã«å¤‰æ›\n",
    "    params_df = params.to_frame(name='Parameter_Estimate')\n",
    "\n",
    "    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰åˆ—ã«ç§»å‹•\n",
    "    params_df.reset_index(inplace=True)\n",
    "    params_df = params_df.rename(columns={'index': 'Parameter_Name'})\n",
    "\n",
    "\n",
    "    result = session.create_dataframe(params_df)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ec27d7-64ae-49e7-9b74-2330cd99080a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
