{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75297f62-e885-4efa-8a11-8a9d6705516e",
   "metadata": {},
   "source": [
    "# DEMO1\n",
    "\n",
    "以下のコードはSnowpark ML Demo( https://github.com/Snowflake-Labs/snowpark-python-demos/tree/main/snowpark-ml-housing-demo )より引用しました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37072090-3ace-40f4-91e2-8d76dade8859",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 95%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>🦄 Notes: </font></h3>\n",
    "\n",
    "```Python\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "\n",
    "fetch_housing_data()\n",
    "```\n",
    "\n",
    "\n",
    "このコードは、California Housing Pricesデータセット（住宅価格データセット）をインターネットからダウンロードし、ローカルのフォルダに保存するためのものです。以下に、コード内で使用されている主要な関数やメソッドをテーブルにまとめて説明します。\n",
    "\n",
    "| 関数/メソッド | 説明 |\n",
    "|----------------|------|\n",
    "| `import os` | Pythonの`os`モジュールをインポート。ファイルおよびディレクトリの操作に使用する。 |\n",
    "| `import tarfile` | Pythonの`tarfile`モジュールをインポート。tarファイルの操作に使用する。 |\n",
    "| `import urllib.request` | Pythonの`urllib.request`モジュールをインポート。URLからデータをダウンロードするために使用する。 |\n",
    "| `DOWNLOAD_ROOT` | データをダウンロードするための基本URLを指定。 |\n",
    "| `HOUSING_PATH` | ローカルのデータ保存先フォルダのパスを指定。 |\n",
    "| `HOUSING_URL` | ダウンロード対象のデータのURLを指定。 |\n",
    "| `def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):` | データをダウンロードし、ローカルに保存するための関数を定義。関数内で指定したURLからデータをダウンロードし、ローカルのフォルダに保存。 |\n",
    "| `if not os.path.isdir(housing_path):` | ローカルのデータ保存先フォルダが存在しない場合、フォルダを作成する。 |\n",
    "| `os.makedirs(housing_path)` | ディレクトリを作成する関数。 |\n",
    "| `tgz_path = os.path.join(housing_path, \"housing.tgz\")` | ローカルでのtarファイルの保存パスを指定。 |\n",
    "| `urllib.request.urlretrieve(housing_url, tgz_path)` | 指定したURLからファイルをダウンロードしてローカルに保存。 |\n",
    "| `housing_tgz = tarfile.open(tgz_path)` | ダウンロードしたtarファイルを開いて、その中のファイルにアクセスするための`tarfile`オブジェクトを作成。 |\n",
    "| `housing_tgz.extractall(path=housing_path)` | tarファイル内のすべてのファイルを指定したディレクトリに解凍。 |\n",
    "| `housing_tgz.close()` | tarファイルをクローズしてリソースを解放。 |\n",
    "| `fetch_housing_data()` | データのダウンロードと保存を行うために定義した関数を呼び出す。 |\n",
    "\n",
    "このコードの主な目的は、データセットをダウンロードしてローカルに保存し、後続のデータ分析や機械学習モデルのトレーニングに使用するためのデータを用意することです。\n",
    "\n",
    "```\n",
    "* os.path.join() 関数を使用して、ディレクトリパスの生成と結合を行う。(\"datasets\" と \"housing\" という2つのディレクトリ名を結合して、新しいディレクトリパスを作成)\n",
    "* \"datasets\" ディレクトリ内に \"housing\" ディレクトリを作成し、そのパスを HOUSING_PATH 変数に格納"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35c09f5-4c45-4f37-ad05-99d50ed73f78",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 95%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>🦄 Notes: </font></h3>\n",
    "    \n",
    "```Python\n",
    "import pandas as pd\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark.functions import udf\n",
    "# Snowpark\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.types import *\n",
    "\n",
    "\n",
    "def load_housing_data ( housing_path = HOUSING_PATH ): \n",
    "    csv_path = os.path.join ( housing_path , \"housing.csv\" ) \n",
    "    return pd.read_csv ( csv_path ) \n",
    "\n",
    "housing = load_housing_data()\n",
    "housing.head()\n",
    "```\n",
    "\n",
    "このコードは、PythonのPandasライブラリを使用して、California Housing Pricesデータセットをロードし、最初のいくつかの行を表示するためのものです。以下に、コードで使用されている主要なライブラリや関数を説明します。\n",
    "\n",
    "| ライブラリ/関数 | 説明 |\n",
    "|-----------------|------|\n",
    "| `import pandas as pd` | Pandasライブラリをインポート。データフレームを操作するためのライブラリ。 |\n",
    "| `from snowflake.snowpark import functions as F` | SnowflakeのSnowparkライブラリから`functions`モジュールをインポートし、`F`としてエイリアスを付ける。 |\n",
    "| `from snowflake.snowpark.functions import udf` | SnowflakeのSnowparkライブラリから`udf`関数をインポート。ユーザー定義関数を作成するために使用する。 |\n",
    "| `from snowflake.snowpark.session import Session` | SnowflakeのSnowparkライブラリから`Session`クラスをインポート。セッションを作成するために使用する。 |\n",
    "| `from snowflake.snowpark.types import *` | SnowflakeのSnowparkライブラリからすべての型をインポート。データ型を操作するために使用する。 |\n",
    "| `def load_housing_data(housing_path=HOUSING_PATH):` | データをロードするための関数を定義。指定したパスからCSVファイルを読み込んでPandasのデータフレームに変換し、そのデータフレームを返す。 |\n",
    "| `csv_path = os.path.join(housing_path, \"housing.csv\")` | ローカルのデータ保存先フォルダ内にあるCSVファイルのパスを指定。 |\n",
    "| `return pd.read_csv(csv_path)` | 指定したCSVファイルをPandasの`read_csv`関数を使用して読み込み、データフレームとして返す。 |\n",
    "| `housing = load_housing_data()` | `load_housing_data`関数を呼び出して、データセットをロードし、`housing`変数に格納。 |\n",
    "| `housing.head()` | `housing`データフレームの最初のいくつかの行を表示するために、`head`メソッドを呼び出す。 |\n",
    "\n",
    "このコードは、データセットをPandasのデータフレームとしてロードし、その内容を最初のいくつかの行で確認するために使用されています。 Snowflakeの関連ライブラリや関数は、この特定のコードスニペットでは使用されていないようです。 Snowflake関連の機能は、他の部分で使用されている可能性があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d76d83-3c1a-4c92-a4e2-bc577efc8376",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 95%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>🦄 Notes: </font></h3>\n",
    "\n",
    "\n",
    "```Python\n",
    "import json\n",
    "\n",
    "with open('creds.json') as f:\n",
    "    data = json.load(f)\n",
    "    USERNAME = data['username']\n",
    "    PASSWORD = data['password']\n",
    "    SF_ACCOUNT = data['sf_account']\n",
    "    SF_WH = data['sf_wh']\n",
    "    SF_DB = data['sf_db']\n",
    "    SF_SCHEMA = data['sf_schema']\n",
    "\n",
    "CONNECTION_PARAMETERS = {\n",
    "   \"account\": SF_ACCOUNT,\n",
    "   \"user\": USERNAME,\n",
    "   \"password\": PASSWORD,\n",
    "   \"database\": SF_DB,\n",
    "   \"schema\": SF_SCHEMA,\n",
    "   \"warehouse\": SF_WH\n",
    "}\n",
    "session = Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "```\n",
    "提供されたコードは、JSONファイルからSnowflakeデータベースへの接続情報を読み込み、Snowflakeのセッションを設定するためのものです。以下に、コードで使用されている主要な関数やメソッドを表にまとめて説明します。\n",
    "\n",
    "| 関数/メソッド | 説明 |\n",
    "|----------------|------|\n",
    "| `import json` | Pythonの`json`モジュールをインポート。JSONデータの読み書きに使用する。 |\n",
    "| `with open('creds.json') as f:` | 'creds.json'という名前のJSONファイルを読み込む。ファイルを開いた後、`f`としてファイルオブジェクトを扱う。 |\n",
    "| `data = json.load(f)` | JSONファイルを読み込み、その内容をPythonのデータ構造に変換する。このコードでは`data`変数にJSONデータが格納される。 |\n",
    "| `USERNAME = data['username']` | `data`からユーザー名を取得し、`USERNAME`変数に格納。 |\n",
    "| `PASSWORD = data['password']` | `data`からパスワードを取得し、`PASSWORD`変数に格納。 |\n",
    "| `SF_ACCOUNT = data['sf_account']` | `data`からSnowflakeアカウント名を取得し、`SF_ACCOUNT`変数に格納。 |\n",
    "| `SF_WH = data['sf_wh']` | `data`からSnowflakeウェアハウス名を取得し、`SF_WH`変数に格納。 |\n",
    "| `SF_DB = data['sf_db']` | `data`からSnowflakeデータベース名を取得し、`SF_DB`変数に格納。 |\n",
    "| `SF_SCHEMA = data['sf_schema']` | `data`からSnowflakeスキーマ名を取得し、`SF_SCHEMA`変数に格納。 |\n",
    "| `CONNECTION_PARAMETERS = {...}` | Snowflakeデータベースへの接続に使用される接続情報を辞書型のオブジェクトで設定。 |\n",
    "| `session = Session.builder.configs(CONNECTION_PARAMETERS).create()` | Snowflakeのセッションを作成。指定した接続情報を使用してセッションを設定し、`session`変数にセッションオブジェクトを格納。 |\n",
    "\n",
    "このコードは、JSONファイルから取得したSnowflakeデータベースへの接続情報を使用して、Snowflakeのセッションを確立します。セッションを確立することで、Snowflakeデータベースへのクエリ実行などの操作が可能になります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f33a45c-5830-45ac-98d4-75496d770550",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 95%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>🦄 Notes: </font></h3>\n",
    "\n",
    "```Python\n",
    "%%time\n",
    "\n",
    "query = \"create or replace table HOUSING_DATA (LONGITUDE float,LATITUDE float,HOUSING_MEDIAN_AGE float,\" +\\\n",
    "        \"TOTAL_ROOMS float,TOTAL_BEDROOMS float,POPULATION float,HOUSEHOLDS float,\" +\\\n",
    "        \"MEDIAN_INCOME float,MEDIAN_HOUSE_VALUE float,OCEAN_PROXIMITY varchar)\"\n",
    "        \n",
    "session.sql(query).collect()\n",
    "```\n",
    "\n",
    "提供されたコードは、Snowflakeデータベース内に新しいテーブルを作成するためのSQLクエリを実行するものです。また、コードを実行するのにかかる時間も計測しています。以下に、コードで使用されている主要な関数やメソッドを表にまとめて説明します。\n",
    "\n",
    "| 関数/メソッド | 説明 |\n",
    "|----------------|------|\n",
    "| `%%time` | Jupyter Notebookなどの環境で実行時間を計測するためのマジックコマンド。 |\n",
    "| `query = \"create or replace table HOUSING_DATA ...\"` | データベースに新しいテーブルを作成するためのSQLクエリを作成。このSQLクエリは、HOUSING_DATAという名前のテーブルを作成し、テーブルの列とデータ型を定義しています。 |\n",
    "| `session.sql(query).collect()` | `session`オブジェクトを使用して、作成したSQLクエリをデータベースに送信し、実行。`collect()`メソッドはクエリの結果を収集し、必要な場合に表示する。 |\n",
    "\n",
    "このコードは、新しいデータベーステーブルを作成するためのSQLクエリを実行しています。テーブルは \"HOUSING_DATA\" という名前で作成され、さまざまな列とデータ型が定義されています。データベース内にテーブルを作成することで、データの保存やクエリ実行のためのテーブルを用意することができます。また、`%%time`を使用して、クエリの実行にかかる時間を計測しています。\n",
    "```\n",
    "* create or replace table ステートメントを使用して、名前が \"HOUSING_DATA\" のテーブルを作成\n",
    "* カラム名とその型を指定。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0f7bc3-2b06-43a2-ad2e-b893876f1e13",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 95%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>🦄 Notes: </font></h3>\n",
    "\n",
    "```Python\n",
    "# need to convert column names to upper case before writing into Snowflake\n",
    "housing.columns = [x.upper() for x in housing.columns]\n",
    "housing.head()\n",
    "```\n",
    "提供されたコードは、Pandasデータフレーム内の列名（カラム名）を大文字に変換する操作を実行しています。大文字に変換した列名は、おそらくSnowflakeデータベースにデータを書き込む際に使用されることを意味します。以下に、コードで使用されている主要な関数やメソッドを表にまとめて説明します。\n",
    "\n",
    "| 関数/メソッド | 説明 |\n",
    "|----------------|------|\n",
    "| `housing.columns` | データフレームの列名を含む属性。 |\n",
    "| `housing.columns = [x.upper() for x in housing.columns]` | リスト内包表記を使用して、データフレームの列名を大文字に変換しています。新しい列名は元の列名の大文字バージョンに置き換えられます。 |\n",
    "| `housing.head()` | データフレームの最初のいくつかの行を表示するために`head`メソッドを呼び出しています。 |\n",
    "\n",
    "このコードは、データフレーム内の列名を大文字に変換することで、データフレームの列名をSnowflakeデータベースとの互換性に合わせています。 Snowflakeデータベースは一般的に大文字を使用するため、データの書き込みやクエリ実行に適した形式にデータフレームを変更しています。\n",
    "\n",
    "```\n",
    "* 既にあるhousingというデータのカラム名を変更"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eb65d4-f184-4b00-b615-067f1718c8c1",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 95%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>🦄 Notes: </font></h3>\n",
    "\n",
    "```Python\n",
    "snowpark_df = session.write_pandas(housing, \"HOUSING_DATA\")\n",
    "```\n",
    "提供されたコードは、SnowflakeデータベースにPandasデータフレーム（`housing`）を書き込むための操作を実行しています。以下に、コードで使用されている関数やメソッドを説明します。\n",
    "\n",
    "| 関数/メソッド | 説明 |\n",
    "|----------------|------|\n",
    "| `session.write_pandas(housing, \"HOUSING_DATA\")` | `session`オブジェクトを使用して、Pandasデータフレーム `housing` を \"HOUSING_DATA\" という名前のSnowflakeデータベーステーブルに書き込む操作を実行。Snowflakeデータベースにデータを書き込むためのメソッド。 `housing` データフレームの内容が指定されたテーブルに書き込まれる。 `write_pandas`メソッドは、PandasデータフレームをSnowflakeテーブルに書き込むのに便利な方法です。 |\n",
    "\n",
    "このコードは、`housing` データフレームの内容を指定したSnowflakeデータベーステーブルに書き込みます。この操作により、PandasデータをSnowflakeデータベースに移行し、データベース内でクエリ実行や分析を行うことができるようになります。\n",
    "\n",
    "```\n",
    "* データフレーム housing を \"HOUSING_DATA\" というテーブルに書き込む"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120837f2-aae5-495b-bb43-6dbbf901effb",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 95%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>🦄 Notes: </font></h3>\n",
    "\n",
    "```Python\n",
    "snowpark_df.toPandas().head()\n",
    "```\n",
    "\n",
    "提供されたコードは、Snowflakeデータベースからデータを取得し、それをPandasデータフレームに変換して最初のいくつかの行を表示する操作を実行しています。以下に、コードで使用されている関数やメソッドを説明します。\n",
    "\n",
    "| 関数/メソッド | 説明 |\n",
    "|----------------|------|\n",
    "| `snowpark_df.toPandas()` | `snowpark_df` というSnowflakeデータフレームをPandasデータフレームに変換する操作。これにより、Snowflakeデータベースから取得したデータがPandasデータフレームとして扱えるようになります。 |\n",
    "| `.head()` | データフレームの最初のいくつかの行を表示するためのPandasのメソッド。 |\n",
    "\n",
    "このコードは、`snowpark_df` からSnowflakeデータベース内のデータを取得し、それをPandasデータフレームに変換して、そのデータフレームの最初のいくつかの行を表示しています。これにより、Snowflakeデータベースから取得したデータをPandasを使用して分析や視覚化などの作業を行うために利用できます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac5665c-4ec2-4a8b-953a-7a901154faaa",
   "metadata": {},
   "source": [
    "# DEMO2\n",
    "\n",
    "このノートブックでは、Scikit-Learn MLパイプラインを訓練します。このパイプラインには、欠損値の補完、スケーリング、ワンホットエンコーディングなどの一般的な特徴エンジニアリングタスクが含まれています。また、RandomForestRegressorモデルも含まれており、カリフォルニアの中央住宅価格を予測します。\n",
    "\n",
    "このパイプラインを、Snowpark Python Stored Procedure（SPROC）を使用して訓練し、保存します。そして、保存されたモデル/パイプラインをSnowflakeのステージに保存し、Snowpark Python User-Defined Functions（UDFs）を使用して、Snowflakeワーキングプール上でスケーラブルに読み込んで実行する方法を示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146f8d9d-1d05-4e22-b2a4-ba2d80456172",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 95%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>🦄 Notes: </font></h3>\n",
    "\n",
    "```Python\n",
    "# Snowpark\n",
    "import datetime\n",
    "import io\n",
    "import json\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import snowflake.snowpark\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from snowflake.snowpark import version as v\n",
    "from snowflake.snowpark.functions import sproc\n",
    "from snowflake.snowpark.session import Session\n",
    "\n",
    "with open('creds.json') as f:\n",
    "    data = json.load(f)\n",
    "    USERNAME = data['username']\n",
    "    PASSWORD = data['password']\n",
    "    SF_ACCOUNT = data['sf_account']\n",
    "    SF_WH = data['sf_wh']\n",
    "    SF_DB = data['sf_db']\n",
    "    SF_SCHEMA = data['sf_schema']\n",
    "\n",
    "CONNECTION_PARAMETERS = {\n",
    "   \"account\": SF_ACCOUNT,\n",
    "   \"user\": USERNAME,\n",
    "   \"password\": PASSWORD,\n",
    "   \"database\": SF_DB,\n",
    "   \"schema\": SF_SCHEMA,\n",
    "   \"warehouse\": SF_WH\n",
    "}\n",
    "\n",
    "session = Session.builder.configs(CONNECTION_PARAMETERS).create()\n",
    "session.add_packages('snowflake-snowpark-python', 'scikit-learn', 'pandas', 'numpy', 'joblib', 'cachetools')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b17bde2-65db-4511-a914-ddcd40fc2e5f",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 95%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>🦄 Notes: </font></h3>\n",
    "\n",
    "```Python\n",
    "\n",
    "query = \"create or replace stage models\" +\\\n",
    "        \" directory = (enable = true)\" +\\\n",
    "        \" copy_options = (on_error='skip_file')\"\n",
    "        \n",
    "session.sql(query).collect()\n",
    "```\n",
    "\n",
    "提供されたコードは、Snowflakeデータベース内に新しいステージ（stage）を作成するためのSQLクエリを実行するものです。以下に、コードで使用されている関数やメソッドを説明します。\n",
    "\n",
    "| 関数/メソッド | 説明 |\n",
    "|----------------|------|\n",
    "| `query = \"create or replace stage models\" + ...` | 新しいステージ（stage）を作成するためのSQLクエリを作成。このSQLクエリは、\"models\" という名前のステージを作成し、ステージの設定情報を指定しています。 |\n",
    "| `session.sql(query)` | `session`オブジェクトを使用して、作成したSQLクエリをデータベースに送信する操作。 |\n",
    "| `.collect()` | SQLクエリの実行結果を収集する操作。この場合、クエリの実行結果に関連するデータが収集され、必要に応じて表示されます。 |\n",
    "\n",
    "このコードは、\"models\" という名前のステージを作成し、そのステージの設定情報を指定しています。ステージは、データの一時的な保管場所として使用され、データのアップロードやダウンロードに利用できます。この操作により、Snowflakeデータベース内でのデータの管理や移動が容易になります。\n",
    "\n",
    "```\n",
    "* \" directory = (enable = true)\" : データステージのディレクトリを有効にし、データを格納するためのディレクトリを作成\n",
    "* \"copy_options = (on_error='skip_file')\": データのコピー時にエラーが発生した場合、ファイルをスキップするオプションを設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4117dbb-ee4f-45a1-b671-066d821f62b9",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 95%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>🦄 Notes: </font></h3>\n",
    "\n",
    "```Python\n",
    "query = \"create or replace stage udf\" +\\\n",
    "        \" copy_options = (on_error='skip_file')\"\n",
    "        \n",
    "session.sql(query).collect()\n",
    "```\n",
    "提供されたコードは、Snowflakeデータベース内に新しいステージ（stage）を作成するためのSQLクエリを実行するものです。以下に、コードで使用されている関数やメソッドを説明します。\n",
    "\n",
    "| 関数/メソッド | 説明 |\n",
    "|----------------|------|\n",
    "| `query = \"create or replace stage udf\" + ...` | 新しいステージ（stage）を作成するためのSQLクエリを作成。このSQLクエリは、\"udf\" という名前のステージを作成し、ステージの設定情報を指定しています。 |\n",
    "| `session.sql(query)` | `session`オブジェクトを使用して、作成したSQLクエリをデータベースに送信する操作。 |\n",
    "| `.collect()` | SQLクエリの実行結果を収集する操作。この場合、クエリの実行結果に関連するデータが収集され、必要に応じて表示されます。 |\n",
    "\n",
    "このコードは、\"udf\" という名前のステージを作成し、そのステージの設定情報を指定しています。ステージは、データの一時的な保管場所として使用され、データのアップロードやダウンロードに利用できます。新しいステージを作成することで、データの一時的な保管や処理に役立つ場所を確保できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6961e10d-292e-42d1-8282-35ec9cda9eff",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 95%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>🦄 Notes: </font></h3>\n",
    "\n",
    "```Python\n",
    "def save_file(session, model, path):\n",
    "  input_stream = io.BytesIO()\n",
    "  joblib.dump(model, input_stream)\n",
    "  session._conn._cursor.upload_stream(input_stream, path)\n",
    "  return \"successfully created file: \" + path\n",
    "```\n",
    "提供されたコードは、指定されたモデルオブジェクトを指定されたパスに保存するための関数です。以下に、関数内で使用されている主要な関数やメソッドを説明します。\n",
    "\n",
    "| 関数/メソッド | 説明 |\n",
    "|----------------|------|\n",
    "| `def save_file(session, model, path):` | ファイルを保存するための関数を定義。引数として、`session`オブジェクト、モデルオブジェクト、および保存先のパス（path）を受け取ります。 |\n",
    "| `input_stream = io.BytesIO()` | `io.BytesIO()`を使用して、バイトデータをメモリ内のバッファに書き込むためのストリームオブジェクト（`input_stream`）を作成。 |\n",
    "| `joblib.dump(model, input_stream)` | `joblib`モジュールを使用して、モデルオブジェクトを指定したバイトストリーム（`input_stream`）にシリアライズして保存。 |\n",
    "| `session._conn._cursor.upload_stream(input_stream, path)` | `session`オブジェクトの内部メソッド（`_conn._cursor.upload_stream`）を使用して、バイトストリーム内のデータを指定したパス（`path`）にアップロード。 |\n",
    "| `return \"successfully created file: \" + path` | ファイルが正常に作成されたことを示すメッセージを返し、保存されたファイルのパスを含めて返します。 |\n",
    "\n",
    "この関数は、モデルオブジェクトを指定されたパスにシリアライズして保存するために使用されます。保存先のパスにファイルが正常に作成された場合、\"successfully created file\" とそのファイルのパスが返されます。この関数は、モデルの保存やファイルのアップロードなどのデータ操作に役立ちます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d77684-511f-4842-9a9d-7a760bb239a4",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 95%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>🦄 Notes: </font></h3>\n",
    "\n",
    "```Python\n",
    "def train_model(session: snowflake.snowpark.Session) -> float:\n",
    "    snowdf = session.table(\"HOUSING_DATA\")\n",
    "    # split the train and test set\n",
    "    snowdf_train, snowdf_test = snowdf.random_split([0.8, 0.2], seed=82) # use seed to make the split repeatable\n",
    "    \n",
    "\n",
    "    # save the train and test sets as time stamped tables in Snowflake \n",
    "    snowdf_train.write.mode(\"overwrite\").save_as_table(\"HOUSING_TRAIN\")\n",
    "    snowdf_test.write.mode(\"overwrite\").save_as_table(\"HOUSING_TEST\")\n",
    "    \n",
    "    housing = snowdf_train.drop(\"MEDIAN_HOUSE_VALUE\").to_pandas() # drop labels for training set\n",
    "    housing_labels = snowdf_train.select(\"MEDIAN_HOUSE_VALUE\").to_pandas()\n",
    "    housing_test = snowdf_test.drop(\"MEDIAN_HOUSE_VALUE\").to_pandas()\n",
    "    housing_test_labels = snowdf_test.select(\"MEDIAN_HOUSE_VALUE\").to_pandas()\n",
    "\n",
    "    # numerical features\n",
    "    housing_num = housing.drop(\"OCEAN_PROXIMITY\", axis=1)\n",
    "    # create a pipeline for numerical features\n",
    "    num_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "            ('std_scaler', StandardScaler()),\n",
    "        ])\n",
    "\n",
    "    num_attribs = list(housing_num)\n",
    "    cat_attribs = [\"OCEAN_PROXIMITY\"]\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "            (\"num\", num_pipeline, num_attribs),\n",
    "            (\"cat\", OneHotEncoder(), cat_attribs)\n",
    "        ])\n",
    "\n",
    "    full_pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "        ])\n",
    "\n",
    "    # fit the preprocessing pipeline and the model together\n",
    "    full_pipeline.fit(housing, housing_labels)\n",
    "\n",
    "    # save the full pipeline including the model\n",
    "    save_file(session, full_pipeline, \"@MODELS/housing_fores_reg.joblib\")\n",
    "\n",
    "    # predict on the test set and return the root mean squared error (RMSE)\n",
    "    housing_predictions = full_pipeline.predict(housing_test)\n",
    "    lin_mse = mean_squared_error(housing_test_labels, housing_predictions)\n",
    "    lin_rmse = np.sqrt(lin_mse)\n",
    "    return lin_rmse\n",
    "```\n",
    "提供されたコードは、機械学習モデルのトレーニング、評価、およびモデルの保存を行う操作を含む関数です。以下に、コード内で使用されている主要な関数やメソッド、設定、および手順をまとめて説明します。\n",
    "\n",
    "| 関数/メソッド | 説明 |\n",
    "|----------------|------|\n",
    "| `def train_model(session: snowflake.snowpark.Session) -> float:` | モデルのトレーニングと評価を行うための関数を定義。関数は`session`オブジェクトを受け取り、RMSE（平均二乗誤差の平方根）を返します。 |\n",
    "| `snowdf = session.table(\"HOUSING_DATA\")` | Snowflakeデータベースから \"HOUSING_DATA\" テーブルを読み込む。 |\n",
    "| `snowdf_train, snowdf_test = snowdf.random_split([0.8, 0.2], seed=82)` | データをトレーニングセットとテストセットにランダムに分割。分割にはseed（乱数のシード値）を使用して、分割を再現可能にする。 |\n",
    "| `snowdf_train.write.mode(\"overwrite\").save_as_table(\"HOUSING_TRAIN\")` | トレーニングデータを \"HOUSING_TRAIN\" という名前のテーブルとしてSnowflakeデータベースに保存。 |\n",
    "| `snowdf_test.write.mode(\"overwrite\").save_as_table(\"HOUSING_TEST\")` | テストデータを \"HOUSING_TEST\" という名前のテーブルとしてSnowflakeデータベースに保存。 |\n",
    "| `housing = snowdf_train.drop(\"MEDIAN_HOUSE_VALUE\").to_pandas()` | トレーニングデータから目的変数 \"MEDIAN_HOUSE_VALUE\" を削除し、特徴量データをPandasデータフレームに変換。 |\n",
    "| `housing_labels = snowdf_train.select(\"MEDIAN_HOUSE_VALUE\").to_pandas()` | トレーニングデータの目的変数 \"MEDIAN_HOUSE_VALUE\" をPandasデータフレームとして取得。 |\n",
    "| `housing_test = snowdf_test.drop(\"MEDIAN_HOUSE_VALUE\").to_pandas()` | テストデータから目的変数 \"MEDIAN_HOUSE_VALUE\" を削除し、特徴量データをPandasデータフレームに変換。 |\n",
    "| `housing_test_labels = snowdf_test.select(\"MEDIAN_HOUSE_VALUE\").to_pandas()` | テストデータの目的変数 \"MEDIAN_HOUSE_VALUE\" をPandasデータフレームとして取得。 |\n",
    "| `num_pipeline = Pipeline([...])` | 数値特徴量用のデータ前処理パイプラインを定義。欠損値の補完と標準化を行う。 |\n",
    "| `preprocessor = ColumnTransformer([...])` | 特徴量の前処理用のカスタム前処理パイプラインを定義。数値特徴量とカテゴリカル特徴量に異なる処理を適用。 |\n",
    "| `full_pipeline = Pipeline([...])` | フルパイプラインを定義。前処理とモデル（ランダムフォレスト回帰）を組み合わせる。 |\n",
    "| `full_pipeline.fit(housing, housing_labels)` | フルパイプラインをトレーニングデータに適合させる。 |\n",
    "| `save_file(session, full_pipeline, \"@MODELS/housing_fores_reg.joblib\")` | モデルを保存するための `save_file` 関数を呼び出し、トレーニング済みのモデルを指定したパスに保存。 |\n",
    "| `housing_predictions = full_pipeline.predict(housing_test)` | テストデータに対するモデルの予測を実行。 |\n",
    "| `lin_mse = mean_squared_error(housing_test_labels, housing_predictions)` | 平均二乗誤差（MSE）を計算。 |\n",
    "| `lin_rmse = np.sqrt(lin_mse)` | 平均二乗誤差の平方根（RMSE）を計算。 |\n",
    "| `return lin_rmse` | RMSEを返し、モデルの評価結果として出力。 |\n",
    "\n",
    "このコードは、データ分析および機械学習のワークフローを実行しており、データの前処理、モデルのトレーニング、モデルの評価、およびモデルの保存の各ステップを含んでいます。関数はRMSE（平均二乗誤差の平方根）を返し、モデルの性能評価を提供します。また、モデルはトレーニング済みで、データベース内に保存されています。\n",
    "```R\n",
    " * save_file(session, full_pipeline, \"@MODELS/housing_fores_reg.joblib\"は、full_pipeline という機械学習パイプラインを指定の場所に保存するための操作を実行する。\n",
    "* \"@MODELS/housing_fores_reg.joblib\" は、データベース内の MODELS というデータステージ内にある housing_fores_reg.joblib というファイルへのパスを表す。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1949ee6c-5363-4beb-b254-40c1ffb3e0c9",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 95%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>🦄 Notes: </font></h3>\n",
    "\n",
    "```Python\n",
    "# Create an instance of StoredProcedure using the sproc() function\n",
    "train_model_sp = sproc(train_model, replace=True)\n",
    "```\n",
    "\n",
    "提供されたコードは、StoredProcedure（ストアドプロシージャ）のインスタンスを作成するための操作を示しています。以下に、コードで使用されている関数やメソッドを説明します。\n",
    "\n",
    "| 関数/メソッド | 説明 |\n",
    "|----------------|------|\n",
    "| `train_model_sp = sproc(train_model, replace=True)` | `sproc()`関数を使用して、`train_model`という関数をStoredProcedureのインスタンスとして作成。`replace=True`パラメータは、同じ名前のストアドプロシージャが既に存在する場合に、それを置き換えることを指定します。 |\n",
    "\n",
    "このコードは、`train_model`という関数をStoredProcedureとして実行可能な形式に変換し、`train_model_sp`という変数にそのインスタンスを格納します。ストアドプロシージャは通常、データベース内での特定の処理やタスクを実行するために使用されます。この例では、`train_model`関数をStoredProcedureとして実行できるようにしています。\n",
    "\n",
    "```\n",
    "* ユーザー定義関数(UDF):必要とする処理を自分で記述して作成した関数。\n",
    "* ストアドプロシージャ:実行する複数のSQL文をまとめ、プログラムのようなものとしてDBMS内に保存し、データベースの外部から呼び出すもの。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4972935c-ccc5-4b91-97be-db338a909ea0",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 95%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>🦄 Notes: </font></h3>\n",
    "\n",
    "```Python\n",
    "train_model_sp()\n",
    "```\n",
    "提供されたコードは、StoredProcedureである `train_model_sp` を実行する操作を示しています。具体的には、`train_model_sp()` という呼び出しを行っています。これにより、StoredProcedure内の `train_model` 関数が実行され、モデルのトレーニング、評価、および保存が実行されるでしょう。\n",
    "\n",
    "StoredProcedureは、通常はデータベース内で特定の処理やタスクを実行するために使用されます。この場合、StoredProcedure内で機械学習モデルのトレーニングと評価が行われ、その結果が返されるでしょう。実行には時間がかかる可能性があるため、実行が完了するのを待つ必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7667f1-0b99-428e-a6e5-50aae3dfe4a2",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 95%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>🦄 Notes: </font></h3>\n",
    "\n",
    "```Python\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import cachetools\n",
    "from snowflake.snowpark.functions import udf\n",
    "\n",
    "session.add_import(\"@MODELS/housing_fores_reg.joblib\")  \n",
    "\n",
    "@cachetools.cached(cache={})\n",
    "def read_file(filename):\n",
    "       import_dir = sys._xoptions.get(\"snowflake_import_directory\")\n",
    "       if import_dir:\n",
    "              with open(os.path.join(import_dir, filename), 'rb') as file:\n",
    "                     m = joblib.load(file)\n",
    "                     return m\n",
    "\n",
    "features = ['LONGITUDE', 'LATITUDE', 'HOUSING_MEDIAN_AGE', 'TOTAL_ROOMS',\n",
    "       'TOTAL_BEDROOMS', 'POPULATION', 'HOUSEHOLDS', 'MEDIAN_INCOME', 'OCEAN_PROXIMITY']\n",
    "\n",
    "@udf(name=\"predict\", is_permanent=True, stage_location=\"@udf\", replace=True)\n",
    "def predict(LONGITUDE: float, LATITUDE: float, HOUSING_MEDIAN_AGE: float, TOTAL_ROOMS: float, \n",
    "                    TOTAL_BEDROOMS: float, POPULATION: float, HOUSEHOLDS: float, MEDIAN_INCOME: float, \n",
    "                    OCEAN_PROXIMITY: str) -> float:\n",
    "       m = read_file('housing_fores_reg.joblib')       \n",
    "       row = pd.DataFrame([locals()], columns=features)\n",
    "       return m.predict(row)[0]\n",
    "```\n",
    "提供されたコードは、以下の処理を行うためのスクリプトを示しています。各部分について、使用されている関数、メソッド、設定などをまとめて説明します。\n",
    "\n",
    "| 関数/メソッド | 説明 |\n",
    "|----------------|------|\n",
    "| `session.add_import(\"@MODELS/housing_fores_reg.joblib\")` | Snowflakeセッションにモデルファイルのインポートパスを追加。 |\n",
    "| `@cachetools.cached(cache={})` | キャッシュを使用して関数をメモ化するデコレータ。 |\n",
    "| `read_file(filename)` | モデルファイルを読み込む関数。ファイルを指定されたディレクトリから読み込み、モデルオブジェクトを返す。 |\n",
    "| `@udf(name=\"predict\", is_permanent=True, stage_location=\"@udf\", replace=True)` | Snowflakeのユーザー定義関数（UDF）を作成するデコレータ。UDFは予測モデルを呼び出し、予測を返すために使用される。 |\n",
    "| `predict(...)` | UDFとして定義された関数。引数として特徴量を受け取り、モデルを使用して予測を行い、結果を返す。 |\n",
    "\n",
    "このコードの目的は、Snowflakeデータベース内で保存されたモデルファイルを読み込み、そのモデルを使用して予測を行うためのUDFを作成することです。UDFはデータベース内のデータに対して予測を実行するのに役立ちます。\n",
    "\n",
    "```\n",
    "* @cachetools.cached(cache={}) では、デコレータを使用して関数にキャッシュの機能を追加している。引数 cache はキャッシュの設定を指定するための辞書。この辞書内で、キャッシュのサイズ制限やキャッシュのエントリの有効期限などを設定できる。\n",
    "* sys._xoptions.get(\"snowflake_import_directory\") を使用して、Snowflake（データウェアハウスプラットフォーム）のデータインポートディレクトリを取得している。\n",
    "* Snowflakeのデータインポートディレクトリは、データをアップロードまたはダウンロードするためのディレクトリ。\n",
    "* データインポートディレクトリが存在する場合、with ステートメントを使用して指定されたファイル名のファイルをバイナリモードで開く。\n",
    "* joblib.load(file) を使用して、ファイルからデータを読み取る。\n",
    "* @udf()でpredict関数を @udf という名前のステージに保存させる。\n",
    "*  -> float:で返り値を浮動小数点に指定。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49845b77-a504-4b79-9813-68b6f520af6c",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 95%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>🦄 Notes: </font></h3>\n",
    "\n",
    "```Python\n",
    "from snowflake.snowpark import functions as F\n",
    "\n",
    "snowdf_test = session.table(\"HOUSING_TEST\")\n",
    "inputs = snowdf_test.drop(\"MEDIAN_HOUSE_VALUE\")\n",
    "snowdf_results = snowdf_test.select(*inputs,\n",
    "                    predict(*inputs).alias('PREDICTION'), \n",
    "                    (F.col('MEDIAN_HOUSE_VALUE')).alias('ACTUAL_LABEL')\n",
    "                    ).limit(20)\n",
    "                    \n",
    "snowdf_results.to_pandas().head(20)\n",
    "```\n",
    "提供されたコードは、Snowflakeデータベースからテストデータを読み込み、予測を実行して予測結果と実際のラベルを含むデータフレームを作成し、それをPandasデータフレームに変換して表示する操作を示しています。以下に、コードで使用されている関数やメソッド、設定などを説明します。\n",
    "\n",
    "| 関数/メソッド | 説明 |\n",
    "|----------------|------|\n",
    "| `snowdf_test = session.table(\"HOUSING_TEST\")` | Snowflakeデータベースから \"HOUSING_TEST\" テーブルを読み込み、それを `snowdf_test` という名前のSnowflakeデータフレームに格納。 |\n",
    "| `inputs = snowdf_test.drop(\"MEDIAN_HOUSE_VALUE\")` | テストデータから目的変数 \"MEDIAN_HOUSE_VALUE\" を削除し、特徴量データを `inputs` という名前のSnowflakeデータフレームに格納。 |\n",
    "| `predict(*inputs).alias('PREDICTION')` | `predict` UDFを使用して予測を行い、予測結果を \"PREDICTION\" という名前のカラムとして追加。 |\n",
    "| `F.col('MEDIAN_HOUSE_VALUE').alias('ACTUAL_LABEL')` | \"MEDIAN_HOUSE_VALUE\" カラムを \"ACTUAL_LABEL\" という名前のカラムに名前を変更。 |\n",
    "| `snowdf_results = ...` | 上記の操作に基づいて、予測結果と実際のラベルを含む新しいデータフレームを作成し、それを `snowdf_results` という名前のSnowflakeデータフレームに格納。 |\n",
    "| `snowdf_results.to_pandas().head(20)` | `snowdf_results` データフレームをPandasデータフレームに変換し、最初の20行を表示。 |\n",
    "\n",
    "このコードは、モデルを使用してテストデータに対する予測を行い、その結果をデータフレームにまとめて表示します。予測結果と実際のラベルが表示され、モデルの性能評価やデータの理解に役立ちます。\n",
    "\n",
    "```\n",
    "* snowdf_test.select():\n",
    "* snowdf_test データフレームから特定の列を選択。\n",
    "* *inputs は inputs に含まれる列を選択することを意味し、predict(*inputs) は UDF predict を使用して予測し、新しい列 PREDICTION を生成。\n",
    "* (F.col('MEDIAN_HOUSE_VALUE')).alias('ACTUAL_LABEL') は MEDIAN_HOUSE_VALUE 列を ACTUAL_LABEL としてリネーム。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006b0d77-7fab-4370-ac3a-5adbf943d8a1",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 95%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>🦄 Notes: </font></h3>\n",
    "\n",
    "```Python\n",
    "#ベクトル化されたUDFを使用して最適なパフォーマンスを実現します\n",
    "#上記のコードはモデルを並列で実行しますが、予測を行う際に行ごとに実行されます。ベクトル化されたUDFを使用することで、さらに向上させることができます。Snowparkは行を自動的に分割し、各UDF実行にバッチを送信するため、スループットが向上します。\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import cachetools\n",
    "import pandas\n",
    "from snowflake.snowpark import types as T\n",
    "from snowflake.snowpark.functions import pandas_udf\n",
    "\n",
    "features = ['LONGITUDE', 'LATITUDE', 'HOUSING_MEDIAN_AGE', 'TOTAL_ROOMS',\n",
    "       'TOTAL_BEDROOMS', 'POPULATION', 'HOUSEHOLDS', 'MEDIAN_INCOME', 'OCEAN_PROXIMITY']\n",
    "\n",
    "session.add_import(\"@MODELS/housing_fores_reg.joblib\")  \n",
    "@cachetools.cached(cache={})\n",
    "def read_file(filename):\n",
    "       import_dir = sys._xoptions.get(\"snowflake_import_directory\")\n",
    "       if import_dir:\n",
    "              with open(os.path.join(import_dir, filename), 'rb') as file:\n",
    "                     m = joblib.load(file)\n",
    "                     return m\n",
    "\n",
    "@pandas_udf(max_batch_size=100)\n",
    "def predict_batch(df: T.PandasDataFrame[float, float, float, float,\n",
    "                                          float, float, float, float, str]) -> T.PandasSeries[float]:\n",
    "       m = read_file('housing_fores_reg.joblib') \n",
    "       df.columns = features\n",
    "       return m.predict(df)\n",
    "```\n",
    "提供されたコードは、ベクトル化されたユーザー定義関数（Vectorized UDFs）を使用して、パフォーマンスを最適化し、予測処理を高速化する操作を示しています。以下に、コードで使用されている関数、メソッド、設定などを説明します。\n",
    "\n",
    "| 関数/メソッド | 説明 |\n",
    "|----------------|------|\n",
    "| `session.add_import(\"@MODELS/housing_fores_reg.joblib\")` | Snowflakeセッションにモデルファイルのインポートパスを追加。 |\n",
    "| `@cachetools.cached(cache={})` | キャッシュを使用して関数をメモ化するデコレータ。 |\n",
    "| `read_file(filename)` | モデルファイルを読み込む関数。ファイルを指定されたディレクトリから読み込み、モデルオブジェクトを返す。 |\n",
    "| `@pandas_udf(max_batch_size=100)` | ベクトル化されたユーザー定義関数（Vectorized UDF）を作成するデコレータ。`max_batch_size` パラメータを指定して、UDFのバッチ処理の最大サイズを設定。 |\n",
    "| `predict_batch(...)` | UDFとして定義された関数。Pandasデータフレームをバッチとして処理し、モデルを使用して一括で予測を行い、結果を返す。 |\n",
    "\n",
    "このコードは、パフォーマンスを向上させ、予測処理を高速化するためにベクトル化されたUDFを使用しています。ベクトル化されたUDFは、データフレームのバッチを効率的に処理し、各バッチに対してモデル予測を一括で実行します。これにより、処理の高速化とスループットの向上が期待されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1ae7e0-c21d-4f37-a36c-4e5bda9679d9",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 10px; border: #DEB887 solid; padding: 15px; background-color: #FFFAF0; font-size: 95%; text-align: left\">\n",
    "<h3 align=\"left\"><font color='#3498DB'>🦄 Notes: </font></h3>\n",
    "\n",
    "```Python\n",
    "from snowflake.snowpark import functions as F\n",
    "\n",
    "snowdf_test = session.table(\"HOUSING_TEST\")\n",
    "inputs = snowdf_test.drop(\"MEDIAN_HOUSE_VALUE\")\n",
    "snowdf_results = snowdf_test.select(*inputs,\n",
    "                    predict_batch(*inputs).alias('PREDICTION'), \n",
    "                    (F.col('MEDIAN_HOUSE_VALUE')).alias('ACTUAL_LABEL')\n",
    "                    ).limit(20)\n",
    "                    \n",
    "snowdf_results.to_pandas().head(20)\n",
    "```\n",
    "提供されたコードは、ベクトル化されたユーザー定義関数（Vectorized UDF）を使用して、テストデータに対する予測を高速化し、予測結果と実際のラベルを含むデータフレームを作成し、それをPandasデータフレームに変換して表示する操作を示しています。以下に、コードで使用されている関数やメソッド、設定などを説明します。\n",
    "\n",
    "| 関数/メソッド | 説明 |\n",
    "|----------------|------|\n",
    "| `snowdf_test = session.table(\"HOUSING_TEST\")` | Snowflakeデータベースから \"HOUSING_TEST\" テーブルを読み込み、それを `snowdf_test` という名前のSnowflakeデータフレームに格納。 |\n",
    "| `inputs = snowdf_test.drop(\"MEDIAN_HOUSE_VALUE\")` | テストデータから目的変数 \"MEDIAN_HOUSE_VALUE\" を削除し、特徴量データを `inputs` という名前のSnowflakeデータフレームに格納。 |\n",
    "| `predict_batch(*inputs).alias('PREDICTION')` | `predict_batch` ベクトル化されたUDFを使用して、予測を一括で行い、予測結果を \"PREDICTION\" という名前のカラムとして追加。 |\n",
    "| `(F.col('MEDIAN_HOUSE_VALUE')).alias('ACTUAL_LABEL')` | \"MEDIAN_HOUSE_VALUE\" カラムを \"ACTUAL_LABEL\" という名前のカラムに名前を変更。 |\n",
    "| `snowdf_results = ...` | 上記の操作に基づいて、予測結果と実際のラベルを含む新しいデータフレームを作成し、それを `snowdf_results` という名前のSnowflakeデータフレームに格納。 |\n",
    "| `snowdf_results.to_pandas().head(20)` | `snowdf_results` データフレームをPandasデータフレームに変換し、最初の20行を表示。 |\n",
    "\n",
    "このコードは、ベクトル化されたUDFを使用してテストデータに対する予測を高速化し、その結果をデータフレームにまとめて表示します。予測結果と実際のラベルが表示され、モデルの性能評価やデータの理解に役立ちます。ベクトル化されたUDFを使用することで、予測処理の高速化が実現されます。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
